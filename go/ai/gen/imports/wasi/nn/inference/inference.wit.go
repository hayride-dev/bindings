// Code generated by wit-bindgen-go. DO NOT EDIT.

// Package inference represents the imported interface "wasi:nn/inference@0.2.0-rc-2024-10-28".
//
// An inference "session" is encapsulated by a `graph-execution-context`. This structure
// binds a
// `graph` to input tensors before `compute`-ing an inference:
package inference

import (
	"github.com/hayride-dev/bindings/go/ai/gen/imports/wasi/nn/errors"
	"github.com/hayride-dev/bindings/go/ai/gen/imports/wasi/nn/tensor"
	"go.bytecodealliance.org/cm"
)

// Error represents the imported type alias "wasi:nn/inference@0.2.0-rc-2024-10-28#error".
//
// See [errors.Error] for more information.
type Error = errors.Error

// Tensor represents the imported type alias "wasi:nn/inference@0.2.0-rc-2024-10-28#tensor".
//
// See [tensor.Tensor] for more information.
type Tensor = tensor.Tensor

// NamedTensor represents the imported tuple "wasi:nn/inference@0.2.0-rc-2024-10-28#named-tensor".
//
// Identify a tensor by name; this is necessary to associate tensors to
// graph inputs and outputs.
//
//	type named-tensor = tuple<string, tensor>
type NamedTensor cm.Tuple[string, Tensor]

// GraphExecutionContext represents the imported resource "wasi:nn/inference@0.2.0-rc-2024-10-28#graph-execution-context".
//
// Bind a `graph` to the input and output tensors for an inference.
//
// TODO: this may no longer be necessary in WIT
// (https://github.com/WebAssembly/wasi-nn/issues/43)
//
//	resource graph-execution-context
type GraphExecutionContext cm.Resource

// ResourceDrop represents the imported resource-drop for resource "graph-execution-context".
//
// Drops a resource handle.
//
//go:nosplit
func (self GraphExecutionContext) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_GraphExecutionContextResourceDrop((uint32)(self0))
	return
}

// Compute represents the imported method "compute".
//
// Compute the inference on the given inputs.
//
//	compute: func(inputs: list<named-tensor>) -> result<list<named-tensor>, error>
//
//go:nosplit
func (self GraphExecutionContext) Compute(inputs cm.List[NamedTensor]) (result cm.Result[cm.List[NamedTensor], cm.List[NamedTensor], Error]) {
	self0 := cm.Reinterpret[uint32](self)
	inputs0, inputs1 := cm.LowerList(inputs)
	wasmimport_GraphExecutionContextCompute((uint32)(self0), (*NamedTensor)(inputs0), (uint32)(inputs1), &result)
	return
}
